{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.  First clean the data set as much as we can, i.e filter only what we want, rename variables for clean format, take all null values from all the datasets. I have mostly done this and but I am still working on the 311 dataset. Sana has worked on the zipcodeconversion notebook. So in total we will have 3 jupyter notebooks- sharedmobility, 311 and ziptractconversion.  \n",
    "2. This step is done by Sana today but would be helpful if can tally and crosscheck the data accuracy of the merge dataframe. This should be in separate notebook. Again analze this merged data set and clean up. \n",
    "3. Convert this to a clean_df.csv so that we create read it in a new notebook and start visualization using this csv file instead api requests everytime. Lets take up visualization tasks on Tuesday. \n",
    "4. Recognize all the hypothesis questions and tackle them one by one. Plotting comes as a part of this.\n",
    "5. Decide on visualization and glyphs types? Graphs should be “More Data, Less Ink”, Easy to read but not boring.\n",
    "6. Converting dataframe to sql. Need to watch Eds video on this. \n",
    "7. Create a a notebook ‘Presentation.ipynb’. This will be our final notebook for the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipenv_pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
